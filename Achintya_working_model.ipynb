{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Achintya-dataset(no additions).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dikshuy/hail_UMICaana/blob/master/Achintya_working_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsqTdLU-txVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "d7755d85-6bf3-400b-db70-4cb053323827"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input, ZeroPadding2D, BatchNormalization, Add\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.losses import MAE\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras.layers import Activation\n",
        "from keras import backend as K \n",
        "from keras import regularizers\n",
        "from keras.initializers import glorot_uniform\n",
        "from sklearn.utils import shuffle\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsblP79uA-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f9e78cca-3b9a-4321-be48-bdd651c59bfc"
      },
      "source": [
        "pixel = 64\n",
        "symbols = []\n",
        "alphabets = []\n",
        "\n",
        "\n",
        "img_path = '/content/drive/My Drive/UMIC/Letters'\n",
        "for file in os.listdir('/content/drive/My Drive/UMIC/Letters'):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  alpha = 1\n",
        "  beta = 50\n",
        "  for i in range(-3, 2):\n",
        "    new_img = np.zeros(img.shape, img.dtype)\n",
        "    for y in range(img.shape[0]):\n",
        "        for x in range(img.shape[1]):\n",
        "            for c in range(img.shape[2]):\n",
        "                new_img[y,x,c] = np.clip(alpha*img[y,x,c] + beta*i, 0, 255)\n",
        "    symbols.append(new_img)\n",
        "  alphabets.append(file[0])\n",
        "\n",
        "print(alphabets)\n",
        "print(len(symbols))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['P', 'S', 'L', 'U', 'B', 'O', 'G', 'N', 'C', 'Y', 'K', 'C', 'M', 'F', 'I', 'H', 'A', 'T']\n",
            "90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1HvkXSQNx_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "47954106-318d-4ffb-bfa0-6c65bc8f2113"
      },
      "source": [
        "one_hot = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
        "\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "for j in range(len(symbols)):\n",
        "    symbols[j] = cv2.cvtColor(symbols[j], cv2.COLOR_BGR2GRAY)\n",
        "    data.append(symbols[j])\n",
        "\n",
        "for j in range(len(alphabets)):\n",
        "  for i in range(-3, 2):\n",
        "    label.append(one_hot[j])\n",
        "\n",
        "print(len(label), len(data), len(symbols))\n",
        "\n",
        "for j in range(len(symbols)):\n",
        "  for i in range(-3, 4):\n",
        "    rows, cols = data[j].shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 5*i, 1)\n",
        "    res = cv2.warpAffine(data[j], M, (rows, cols))\n",
        "    label.append(label[j])\n",
        "    data.append(res)\n",
        "\n",
        "for i in range(len(data)):\n",
        "  data[i] = cv2.resize(data[i], (pixel, pixel))\n",
        " \n",
        "print(len(label), len(data))\n",
        "num = len(label)\n",
        "\n",
        "\"\"\"for j in range(num):\n",
        "  height, width = data[j].shape[:2]\n",
        "\n",
        "  dis_y, dis_x = height//10, width//10\n",
        "  T = np.float32([[1, 0, dis_x], [0, 1, dis_y]])\n",
        "\n",
        "  img_trans = cv2.warpAffine(data[j], T, ( width, height))\n",
        "  data.append(img_trans)\n",
        "  label.append(label[j])\n",
        "\n",
        "  T = np.float32([[1, 0, -dis_x], [0, 1, -dis_y]])\n",
        "\n",
        "  img_trans = cv2.warpAffine(data[j], T, ( width, height))\n",
        "  data.append(img_trans)\n",
        "  label.append(label[j])\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90 90 90\n",
            "720 720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'for j in range(num):\\n  height, width = data[j].shape[:2]\\n\\n  dis_y, dis_x = height//10, width//10\\n  T = np.float32([[1, 0, dis_x], [0, 1, dis_y]])\\n\\n  img_trans = cv2.warpAffine(data[j], T, ( width, height))\\n  data.append(img_trans)\\n  label.append(label[j])\\n\\n  T = np.float32([[1, 0, -dis_x], [0, 1, -dis_y]])\\n\\n  img_trans = cv2.warpAffine(data[j], T, ( width, height))\\n  data.append(img_trans)\\n  label.append(label[j])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnBuFAidjyGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ce13e066-1788-4f07-d601-9afe08914334"
      },
      "source": [
        "for j in range(num):\n",
        "  res_img = cv2.GaussianBlur(data[j], (3, 3), 0)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "\n",
        "\n",
        "for j in range(num):\n",
        "  res_img = cv2.medianBlur(data[j], 5)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "\n",
        "\n",
        "for j in range(num):\n",
        "  res_img = cv2.bilateralFilter(data[j], 11, 200, 200)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "l = len(data)\n",
        "for j in range(l):\n",
        "  res_img = cv2.bitwise_not(data[j])\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "\n",
        "\"\"\"for j in range(num):\n",
        "  res_img = cv2.erode(data[j], np.ones((3,3)), iterations = 1)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "\n",
        "for j in range(num):\n",
        "  res_img = cv2.dilate(data[j], np.ones((1, 1), np.uint8), iterations = 1)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "\"\"\"\n",
        "\n",
        "images = np.array(data).reshape(-1, pixel, pixel, 1)\n",
        "print(images.shape)\n",
        "y = np.array(label)\n",
        "print(y.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5760, 64, 64, 1)\n",
            "(5760, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjrzeHmTpUAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "7caba261-9a02-4ca3-a1c5-d3b159801ca5"
      },
      "source": [
        "no = 789\n",
        "print(y[no])\n",
        "print(alphabets)\n",
        "cv2_imshow(images[no].reshape(64, 64, 1))\n",
        "print(alphabets[np.argmax(label[no])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "['P', 'S', 'L', 'U', 'B', 'O', 'G', 'N', 'C', 'Y', 'K', 'C', 'M', 'F', 'I', 'H', 'A', 'T']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F47DE3A81D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "F\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt702m9OB1Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_identity(x, filters, gamma = 0.0001):\n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "  \n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(gamma))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('tanh')(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=regularizers.l2(gamma))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('tanh')(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(gamma))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  #x = Activation('tanh')(x)\n",
        "\n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('tanh')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3brIcO5CXpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_conv(x, s, filters, gamma = 0.0001):\n",
        "  '''\n",
        "  here the input size changes''' \n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=regularizers.l2(gamma))(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('tanh')(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=regularizers.l2(gamma))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('tanh')(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(gamma))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=regularizers.l2(gamma))(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('tanh')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzkTIFkVCh9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet50(input_shape = (pixel, pixel, 1), classes = len(alphabets)):\n",
        "\n",
        "  input_im = Input(input_shape) \n",
        "  x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # 1st stage\n",
        "  # here we perform maxpooling, see the figure above\n",
        "\n",
        "  x = Conv2D(64, kernel_size=(5, 5), strides=(2, 2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "\n",
        "  x = res_conv(x, s=1, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "\n",
        "  # 3rd stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(len(alphabets), activation='softmax', kernel_initializer='he_normal')(x)\n",
        "\n",
        "  # define the model \n",
        "\n",
        "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1shnW7rfBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "outputId": "d1aa4940-217a-4dc6-a14b-e308a01c96dc"
      },
      "source": [
        "model = resnet50()\n",
        "batch_size = 100\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.5)\n",
        "opt1 = tf.keras.optimizers.Adam(learning_rate=0.00003)\n",
        "model.compile(optimizer=opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#images, y = shuffle(images, y, random_state=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.2)\n",
        "\n",
        "#X_train = X_train/255.0\n",
        "#X_test = X_test/255.0\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs= 200, batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 15s 320ms/step - loss: 4.3340 - accuracy: 0.2452 - val_loss: 4.5630 - val_accuracy: 0.1024\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 13s 268ms/step - loss: 3.1250 - accuracy: 0.6860 - val_loss: 3.8427 - val_accuracy: 0.4280\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 13s 268ms/step - loss: 2.3457 - accuracy: 0.8861 - val_loss: 2.9804 - val_accuracy: 0.6701\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 13s 270ms/step - loss: 2.0851 - accuracy: 0.9427 - val_loss: 2.5684 - val_accuracy: 0.8030\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.9412 - accuracy: 0.9789 - val_loss: 2.1947 - val_accuracy: 0.8984\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 13s 272ms/step - loss: 1.9270 - accuracy: 0.9735 - val_loss: 1.9899 - val_accuracy: 0.9427\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 13s 272ms/step - loss: 1.9069 - accuracy: 0.9792 - val_loss: 1.8965 - val_accuracy: 0.9774\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 13s 272ms/step - loss: 1.8744 - accuracy: 0.9870 - val_loss: 1.8932 - val_accuracy: 0.9774\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8566 - accuracy: 0.9902 - val_loss: 1.8698 - val_accuracy: 0.9852\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8424 - accuracy: 0.9922 - val_loss: 1.8403 - val_accuracy: 0.9939\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 13s 272ms/step - loss: 1.8588 - accuracy: 0.9872 - val_loss: 1.8777 - val_accuracy: 0.9792\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8282 - accuracy: 0.9957 - val_loss: 1.8378 - val_accuracy: 0.9931\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8459 - accuracy: 0.9911 - val_loss: 1.8989 - val_accuracy: 0.9696\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8540 - accuracy: 0.9861 - val_loss: 1.8486 - val_accuracy: 0.9887\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 13s 270ms/step - loss: 1.8387 - accuracy: 0.9918 - val_loss: 1.8291 - val_accuracy: 0.9931\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 13s 272ms/step - loss: 1.8174 - accuracy: 0.9970 - val_loss: 1.8148 - val_accuracy: 0.9965\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 13s 274ms/step - loss: 1.8153 - accuracy: 0.9983 - val_loss: 1.8105 - val_accuracy: 0.9983\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8294 - accuracy: 0.9918 - val_loss: 1.8339 - val_accuracy: 0.9896\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8205 - accuracy: 0.9944 - val_loss: 1.8134 - val_accuracy: 0.9974\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8251 - accuracy: 0.9937 - val_loss: 1.8600 - val_accuracy: 0.9809\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8405 - accuracy: 0.9885 - val_loss: 1.9022 - val_accuracy: 0.9705\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8217 - accuracy: 0.9928 - val_loss: 1.8272 - val_accuracy: 0.9922\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 13s 270ms/step - loss: 1.8206 - accuracy: 0.9939 - val_loss: 1.8282 - val_accuracy: 0.9896\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8219 - accuracy: 0.9928 - val_loss: 1.8190 - val_accuracy: 0.9948\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8035 - accuracy: 0.9993 - val_loss: 1.8027 - val_accuracy: 0.9983\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8043 - accuracy: 0.9983 - val_loss: 1.8115 - val_accuracy: 0.9957\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 13s 271ms/step - loss: 1.8005 - accuracy: 0.9993 - val_loss: 1.8009 - val_accuracy: 0.9991\n",
            "Epoch 28/200\n",
            "37/47 [======================>.......] - ETA: 2s - loss: 1.7982 - accuracy: 0.9989"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFDVlfpPMCtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='bottom right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aE3s_Fpb5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = []\n",
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/drive/My Drive/UMIC/A'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  alpha = 1.3\n",
        "  beta = 25\n",
        "  new_img = np.zeros(img.shape, img.dtype)\n",
        "  for y in range(img.shape[0]):\n",
        "      for x in range(img.shape[1]):\n",
        "        new_img[y,x] = np.clip(alpha*img[y,x] + beta, 0, 255)\n",
        "  img = np.array(new_img).reshape(1, pixel, pixel, 1)\n",
        "  predictions = model.predict(img)\n",
        "  t+=1\n",
        "  x = alphabets[np.argmax(predictions[0])]\n",
        "  print(max(predictions[0]))\n",
        "  if max(predictions[0]) < 0.5:\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 1))\n",
        "  if x != 'A':\n",
        "    print(alphabets[np.argmax(predictions)])\n",
        "    print(\"2\", max(predictions[0]))\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 1))\n",
        "    n+=1\n",
        "\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU0MFccE8adj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/drive/My Drive/UMIC/B'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  alpha = 1.3\n",
        "  beta = 25\n",
        "  new_img = np.zeros(img.shape, img.dtype)\n",
        "  for y in range(img.shape[0]):\n",
        "      for x in range(img.shape[1]):\n",
        "        new_img[y,x] = np.clip(alpha*img[y,x] + beta, 0, 255)\n",
        "  img = np.array(new_img).reshape(1, pixel, pixel, 1)\n",
        "  predictions = model.predict(img)\n",
        "  t+=1\n",
        "  x = alphabets[np.argmax(predictions[0])]\n",
        "  print(max(predictions[0]))\n",
        "  if x != 'B':\n",
        "    print(alphabets[np.argmax(predictions)])\n",
        "    print(\"2\", max(predictions[0]))\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 1))\n",
        "    n+=1\n",
        "\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPozMx8sTiHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/drive/My Drive/UMIC/C'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  alpha = 1.3\n",
        "  beta = 25\n",
        "  new_img = np.zeros(img.shape, img.dtype)\n",
        "  for y in range(img.shape[0]):\n",
        "      for x in range(img.shape[1]):\n",
        "        new_img[y,x] = np.clip(alpha*img[y,x] + beta, 0, 255)\n",
        "  img = np.array(new_img).reshape(1, pixel, pixel, 1)\n",
        "  predictions = model.predict(img)\n",
        "  t+=1\n",
        "  x = alphabets[np.argmax(predictions[0])]\n",
        "  print(max(predictions[0]))\n",
        "  if x != 'Y':\n",
        "    print(alphabets[np.argmax(predictions)])\n",
        "    print(\"2\", max(predictions[0]))\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 1))\n",
        "    n+=1\n",
        "\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Pgoifc11m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/drive/My Drive/UMIC/test images'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  alpha = 1.4\n",
        "  beta = 50\n",
        "  new_img = np.zeros(img.shape, img.dtype)\n",
        "  for y in range(img.shape[0]):\n",
        "      for x in range(img.shape[1]):\n",
        "        new_img[y,x] = np.clip(alpha*img[y,x] + beta, 0, 255)\n",
        "  img = np.array(new_img).reshape(1, pixel, pixel, 1)\n",
        "  predictions = model.predict(img)\n",
        "  t+=1\n",
        "  print(alphabets[np.argmax(predictions[0])])\n",
        "  cv2_imshow(img.reshape(pixel, pixel, 1))\n",
        "  #print(max(predictions[0]))\n",
        "  \"\"\"if x != 'C':\n",
        "    print(alphabets[np.argmax(predictions)])\n",
        "    print(\"2\", max(predictions[0]))\n",
        "    \n",
        "    n+=1\n",
        "print(n)\n",
        "print(t)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDsZqAMH9TAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/drive/My Drive/UMIC/Letters/F.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.resize(img, (pixel, pixel))\n",
        "img = np.array(img).reshape(1, pixel, pixel, 1)\n",
        "predictions = model.predict(img)\n",
        "print(alphabets[np.argmax(predictions[0])])\n",
        "print(max(predictions[0]))\n",
        "print(alphabets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS40HkD2Bww7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabets = ['P', 'S', 'L', 'U', 'B', 'O', 'G', 'N', 'C', 'Y', 'K', 'C', 'M', 'F', 'I', 'H', 'A', 'T']\n",
        "img_path = '/content/drive/My Drive/UMIC/Mixed/w8.png'\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.bitwise_not(img)\n",
        "img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "alpha = 1.4\n",
        "beta = 50\n",
        "new_img = np.zeros(img.shape, img.dtype)\n",
        "for y in range(img.shape[0]):\n",
        "    for x in range(img.shape[1]):\n",
        "      new_img[y,x] = np.clip(alpha*img[y,x] + beta, 0, 255)\n",
        "\n",
        "im2 = new_img.copy()\n",
        "gray = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
        "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
        "dilation = cv2.dilate(thresh, rect_kernel, iterations = 5)\n",
        "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "for cnt in contours:\n",
        "  x, y, w, h = cv2.boundingRect(cnt)\n",
        "  if h<100 and w<100:\n",
        "    continue\n",
        "  rect = cv2.rectangle(im2, x, y, x+w, y+h)\n",
        "  cropped = im2[y:y+h, x:x+w]\n",
        "  cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
        "  cv2_imshow(cropped)\n",
        "  cropped = cv2.resize(cropped, (128, 64))\n",
        "  imgs = np.array(cropped).reshape(64, 128)\n",
        "  img1 = imgs[:, :64]\n",
        "  img2 = imgs[:, 64:]\n",
        "\n",
        "  img1 = img1.reshape(1, 64, 64, 1)\n",
        "  img2 = img2.reshape(1, 64, 64, 1)\n",
        "\n",
        "  cv2_imshow(img1.reshape(64, 64))\n",
        "  cv2_imshow(img2.reshape(64, 64))\n",
        "\n",
        "  pred1 = model.predict(img1)\n",
        "  pred2 = model.predict(img2)\n",
        "\n",
        "  l1 = alphabets[np.argmax(pred1[0])]\n",
        "  l2 = alphabets[np.argmax(pred2[0])]\n",
        "\n",
        "letters = l1 + l2\n",
        "print(letters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeNbp4FNNu3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save(\"updated_model_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vnRxR31A17a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save_weights('weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBB-RzxLs6Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}