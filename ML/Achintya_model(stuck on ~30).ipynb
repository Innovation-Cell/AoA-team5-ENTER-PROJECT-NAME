{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Achintya-dataset(no additions).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dikshuy/hail_UMICaana/blob/master/Achintya_model(stuck%20on%20~30).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsqTdLU-txVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b6b88163-7e4a-4bd6-842f-081e24e4b3df"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Input, ZeroPadding2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input, ZeroPadding2D, BatchNormalization, Add\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.losses import MAE\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras.layers import Activation, Dropout, Flatten, Dense \n",
        "from keras import backend as K \n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.initializers import glorot_uniform\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/Letters'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Letters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsblP79uA-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pixel = 64\n",
        "symbols = []\n",
        "alphabets = []\n",
        "\n",
        "img_path = '/content/drive/My Drive/Letters'\n",
        "for file in os.listdir('/content/drive/My Drive/Letters'):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  alpha = 1\n",
        "  beta = 50\n",
        "  for i in range(-3, 2):\n",
        "    new_img = np.zeros(img.shape, img.dtype)\n",
        "    for y in range(img.shape[0]):\n",
        "        for x in range(img.shape[1]):\n",
        "            for c in range(img.shape[2]):\n",
        "                new_img[y,x,c] = np.clip(alpha*img[y,x,c] + beta*i, 0, 255)\n",
        "    symbols.append(new_img)\n",
        "\n",
        "  if file == \"C2.jpg\":\n",
        "    alphabets.append(\"C\")\n",
        "  else:\n",
        "    alphabets.append(file[0])\n",
        "\n",
        "one_hot = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
        "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
        "\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "\n",
        "for j in range(17):\n",
        "  for i in range(-3, 2):\n",
        "    data.append(symbols[j + i + 3])\n",
        "    label.append(one_hot[j])\n",
        "\n",
        "for j in range(17):\n",
        "  for i in range(-5, 6):\n",
        "    rows, cols = data[j].shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 5*i, 1)\n",
        "    res = cv2.warpAffine(data[j], M, (rows, cols))\n",
        "    label.append(one_hot[j])\n",
        "    data.append(res)\n",
        "\n",
        "for i in range(len(data)):\n",
        "  data[i] = cv2.resize(data[i], (pixel, pixel))\n",
        " \n",
        "#print(len(label), len(data))\n",
        "num = len(label)\n",
        "#cv2_imshow(data[100])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnBuFAidjyGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8457b9b3-e05c-42de-8d17-376e16f9bbf8"
      },
      "source": [
        "for j in range(num):\n",
        "  res_img = cv2.GaussianBlur(data[j], (3, 3), 0)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "#cv2_imshow(data[150])\n",
        "#print(len(label), len(data))\n",
        "\n",
        "#for j in range(num):\n",
        "  res_img = cv2.medianBlur(data[j], 5)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "#cv2_imshow(data[250])\n",
        "#print(len(label), len(data))\n",
        "\n",
        "#for j in range(num):\n",
        "  res_img = cv2.bilateralFilter(data[j], 11, 200, 200)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "#cv2_imshow(data[360])\n",
        "#print(len(label), len(data))\n",
        "#print(len(alphabets))\n",
        "\n",
        "#for j in range(num):\n",
        "  res_img = cv2.erode(data[j], np.ones((3,3)), iterations = 1)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "#print(len(label), len(data))\n",
        "#cv2_imshow(data[480])\n",
        "#print(len(alphabets))\n",
        "\n",
        "#for j in range(num):\n",
        "  res_img = cv2.dilate(data[j], np.ones((3, 3), np.uint8), iterations = 1)\n",
        "  data.append(res_img)\n",
        "  label.append(label[j])\n",
        "#cv2_imshow(data[600])\n",
        "#print(len(label), len(data))\n",
        "#print(len(alphabets))\n",
        "\n",
        "images = np.array(data).reshape(-1, pixel, pixel, 3)\n",
        "print(images.shape)\n",
        "y = np.array(label)\n",
        "print(y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1632, 64, 64, 3)\n",
            "(1632, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt702m9OB1Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_identity(x, filters):\n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "  \n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "\n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3brIcO5CXpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_conv(x, s, filters):\n",
        "  '''\n",
        "  here the input size changes''' \n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzkTIFkVCh9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet50(input_shape = (pixel, pixel, 3), classes = len(alphabets)):\n",
        "\n",
        "  input_im = Input(input_shape) \n",
        "  x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # 1st stage\n",
        "  # here we perform maxpooling, see the figure above\n",
        "\n",
        "  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "\n",
        "  x = res_conv(x, s=1, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "\n",
        "  # 3rd stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(len(alphabets), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
        "\n",
        "  # define the model \n",
        "\n",
        "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1shnW7rfBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97177314-b361-4a95-e2f1-74db92437826"
      },
      "source": [
        "model = resnet50()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.2)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = 40, batch_size = 100, validation_data = (X_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "14/14 [==============================] - 3s 207ms/step - loss: 23.0259 - accuracy: 0.1088 - val_loss: 1620.1006 - val_accuracy: 0.0642\n",
            "Epoch 2/40\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 21.6993 - accuracy: 0.1517 - val_loss: 681.8358 - val_accuracy: 0.0489\n",
            "Epoch 3/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 20.9110 - accuracy: 0.1364 - val_loss: 24789.3184 - val_accuracy: 0.0550\n",
            "Epoch 4/40\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 20.3567 - accuracy: 0.1579 - val_loss: 634.3881 - val_accuracy: 0.0642\n",
            "Epoch 5/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 19.4186 - accuracy: 0.1862 - val_loss: 32.0638 - val_accuracy: 0.1315\n",
            "Epoch 6/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 18.9932 - accuracy: 0.2460 - val_loss: 19.0890 - val_accuracy: 0.1315\n",
            "Epoch 7/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 18.7258 - accuracy: 0.2345 - val_loss: 259.0162 - val_accuracy: 0.1682\n",
            "Epoch 8/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 18.5758 - accuracy: 0.1670 - val_loss: 193.6026 - val_accuracy: 0.1040\n",
            "Epoch 9/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 17.2903 - accuracy: 0.2184 - val_loss: 38.2008 - val_accuracy: 0.1437\n",
            "Epoch 10/40\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 16.5682 - accuracy: 0.2743 - val_loss: 16.4253 - val_accuracy: 0.1468\n",
            "Epoch 11/40\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 15.6500 - accuracy: 0.2912 - val_loss: 15.8218 - val_accuracy: 0.1376\n",
            "Epoch 12/40\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 15.2268 - accuracy: 0.2881 - val_loss: 20.5816 - val_accuracy: 0.1162\n",
            "Epoch 13/40\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 15.2255 - accuracy: 0.2590 - val_loss: 276.6810 - val_accuracy: 0.2294\n",
            "Epoch 14/40\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 14.7769 - accuracy: 0.2444 - val_loss: 169.6272 - val_accuracy: 0.1193\n",
            "Epoch 15/40\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 14.5066 - accuracy: 0.2199 - val_loss: 25.0536 - val_accuracy: 0.1774\n",
            "Epoch 16/40\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 13.7421 - accuracy: 0.2820 - val_loss: 15.8650 - val_accuracy: 0.2080\n",
            "Epoch 17/40\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 13.1576 - accuracy: 0.2728 - val_loss: 15.4798 - val_accuracy: 0.1376\n",
            "Epoch 18/40\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 12.7154 - accuracy: 0.3088 - val_loss: 14.2358 - val_accuracy: 0.1743\n",
            "Epoch 19/40\n",
            "14/14 [==============================] - 1s 104ms/step - loss: 12.9084 - accuracy: 0.2736 - val_loss: 445.2151 - val_accuracy: 0.1223\n",
            "Epoch 20/40\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 12.3872 - accuracy: 0.2598 - val_loss: 78.4923 - val_accuracy: 0.1376\n",
            "Epoch 21/40\n",
            "14/14 [==============================] - 1s 105ms/step - loss: 12.0208 - accuracy: 0.2667 - val_loss: 22.6907 - val_accuracy: 0.1621\n",
            "Epoch 22/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 11.6681 - accuracy: 0.2628 - val_loss: 13.1718 - val_accuracy: 0.1284\n",
            "Epoch 23/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 11.3100 - accuracy: 0.2789 - val_loss: 12.0125 - val_accuracy: 0.1621\n",
            "Epoch 24/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 10.8542 - accuracy: 0.2981 - val_loss: 10.9947 - val_accuracy: 0.2110\n",
            "Epoch 25/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 10.6883 - accuracy: 0.2866 - val_loss: 10.8149 - val_accuracy: 0.2263\n",
            "Epoch 26/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 10.2578 - accuracy: 0.3004 - val_loss: 10.5910 - val_accuracy: 0.1713\n",
            "Epoch 27/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 9.9756 - accuracy: 0.2874 - val_loss: 10.2582 - val_accuracy: 0.2171\n",
            "Epoch 28/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 9.5985 - accuracy: 0.3180 - val_loss: 10.2620 - val_accuracy: 0.1927\n",
            "Epoch 29/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 9.3893 - accuracy: 0.3088 - val_loss: 9.7245 - val_accuracy: 0.2416\n",
            "Epoch 30/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 9.2172 - accuracy: 0.2920 - val_loss: 9.6478 - val_accuracy: 0.1682\n",
            "Epoch 31/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 8.8799 - accuracy: 0.3218 - val_loss: 9.3886 - val_accuracy: 0.1927\n",
            "Epoch 32/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 8.7731 - accuracy: 0.2966 - val_loss: 9.2114 - val_accuracy: 0.2080\n",
            "Epoch 33/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 8.4150 - accuracy: 0.3050 - val_loss: 8.8173 - val_accuracy: 0.2997\n",
            "Epoch 34/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 8.2542 - accuracy: 0.2981 - val_loss: 8.8035 - val_accuracy: 0.2691\n",
            "Epoch 35/40\n",
            "14/14 [==============================] - 2s 107ms/step - loss: 8.0180 - accuracy: 0.3234 - val_loss: 8.2577 - val_accuracy: 0.3211\n",
            "Epoch 36/40\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 7.7926 - accuracy: 0.3341 - val_loss: 9.5938 - val_accuracy: 0.2997\n",
            "Epoch 37/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 7.8015 - accuracy: 0.3241 - val_loss: 7.9874 - val_accuracy: 0.3089\n",
            "Epoch 38/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 7.6788 - accuracy: 0.3264 - val_loss: 7.8165 - val_accuracy: 0.2752\n",
            "Epoch 39/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 7.3990 - accuracy: 0.3456 - val_loss: 7.4771 - val_accuracy: 0.3028\n",
            "Epoch 40/40\n",
            "14/14 [==============================] - 1s 107ms/step - loss: 7.3722 - accuracy: 0.3119 - val_loss: 7.4192 - val_accuracy: 0.2783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aE3s_Fpb5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "b45b0d5d-47bd-44d5-8475-212b194a5513"
      },
      "source": [
        "test = []\n",
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/a'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  #blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "  #ret3,th3 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "  #cv2_imshow(th3)\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  img = np.array(img).reshape(1, pixel, pixel, 3)\n",
        "  #cv2_imshow(th3)\n",
        " # print(th3.shape)\n",
        "  #probability_model = Sequential([model])\n",
        "  predictions = model.predict(img)\n",
        "  #print(len(predictions))\n",
        "  #for i in range(len(predictions)):\n",
        "  t+=1\n",
        "  x = alphabets[np.argmax(predictions[0])]\n",
        "  if x != 'A':\n",
        "      #cv2_imshow(blur)\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 3))\n",
        "      #cv2_imshow(th3.reshape(64, 64, 3))\n",
        "    n+=1\n",
        "\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7118105e85b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/a'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU0MFccE8adj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/b'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  img = np.array(img).reshape(1, pixel, pixel, 3)\n",
        "  predictions = model.predict(img)\n",
        "  t+=1\n",
        "  x = alphabets[np.argmax(predictions[0])]\n",
        "  if x != 'B':\n",
        "    #print(alphabets[np.argmax(predictions)])\n",
        "    #print(max(predictions[0]))\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 3))\n",
        "    n+=1\n",
        "\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPozMx8sTiHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = []\n",
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/y'\n",
        "for file in os.listdir(img_path):\n",
        "  img = cv2.imread(os.path.join(img_path, file))\n",
        "  img = cv2.resize(img, (pixel, pixel))\n",
        "  img = np.array(img).reshape(1, pixel, pixel, 3)\n",
        "  predictions = model.predict(img)\n",
        "  t+=1\n",
        "  x = alphabets[np.argmax(predictions[0])]\n",
        "  if x != 'Y':\n",
        "    #print(alphabets[np.argmax(predictions)])\n",
        "    #print(max(predictions[0]))\n",
        "    cv2_imshow(img.reshape(pixel, pixel, 3))\n",
        "    n+=1\n",
        "\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDsZqAMH9TAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 0\n",
        "t = 0\n",
        "img_path = '/content/drive/My Drive/Letters/B.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.resize(img, (pixel, pixel))\n",
        "img = np.array(img).reshape(1, pixel, pixel, 3)\n",
        "predictions = model.predict(img)\n",
        "print(alphabets[np.argmax(predictions[0])])\n",
        "print(max(predictions[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnDSIW6FduZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e0897074-fc84-4cd6-e62e-c1eaddfc76f9"
      },
      "source": [
        "\"\"\"\"\"\"\n",
        "\n",
        "\"\"\"X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\"\"\"\n",
        "\"\"\"print(X_train.shape)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(pixel, pixel, 3), activation='relu', padding = 'same'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(1024, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2048, kernel_constraint=maxnorm(3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "    \n",
        "model.add(Dense(1024, kernel_constraint=maxnorm(3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(18))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "epochs = 100\n",
        "optimizer='adam'\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "seed = 21\n",
        "np.random.seed(seed)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)\"\"\"\n",
        "\n",
        "\"\"\"epochs = 60\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(156, (5, 5), padding='same', activation=tf.nn.relu, input_shape=(64, 64, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2), strides = 2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(156, (5, 5), padding='same', activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2), strides = 2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(156, (5, 5), padding='same', activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2), strides = 2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(296, (3, 3), padding='same', activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2), strides = 2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(296, (3, 3), padding='same', activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2), strides = 2))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(18, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs = epochs, batch_size=64, validation_data=(X_test, y_test))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1468, 64, 64, 3)\n",
            "Epoch 1/100\n",
            "13/46 [=======>......................] - ETA: 15:34 - loss: 3.4665 - accuracy: 0.1394"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}